

# Apache Kafka with Python â€“ A Developer's Practical Guide ğŸš€

Welcome to your end-to-end Kafka learning journey! This project-based repository is built to help you learn and implement Apache Kafka from **scratch to production** using **Python**, **Streamlit**, **Docker**, and **cloud services** like **Confluent Cloud** and **AWS MSK**.

---

## ğŸ“š Table of Contents

- [ğŸ” Overview](#-overview)
- [ğŸ“¦ Kafka Core Concepts](#-kafka-core-concepts)
- [ğŸ’» Local Kafka Setup (Ubuntu)](#-local-kafka-setup-ubuntu)
- [âš™ï¸ CLI Commands](#ï¸-cli-commands)
- [ğŸ Kafka with Python](#-kafka-with-python)
- [ğŸ“ˆ Real-Time Log Processor Project](#-real-time-log-processor-project)
- [ğŸ“Š Streamlit UI for Logs](#-streamlit-ui-for-logs)
- [ğŸ“¢ Notification for Critical Logs](#-notification-for-critical-logs)
- [ğŸ³ Kafka with Docker Compose](#-kafka-with-docker-compose)
- [â˜ï¸ Kafka on Confluent Cloud / AWS MSK](#ï¸-kafka-on-confluent-cloud--aws-msk)
- [ğŸ§  Advanced Kafka](#-advanced-kafka)
- [ğŸ”š Conclusion](#-conclusion)

---

## ğŸ” Overview

This repository guides you through:

- Kafka fundamentals
- Building producers and consumers in Python
- Real-time data processing
- Log visualization with UI
- Deployment via Docker & Cloud

---

## ğŸ“¦ Kafka Core Concepts

- **Topics, Partitions, Offsets**
- **Producers / Consumers**
- **Consumer Groups**
- **Broker & Zookeeper**
- **Serialization / Deserialization**
- **Commit Mechanism: Auto vs Manual**
- **Sync vs Async Producers**

---

## ğŸ’» Local Kafka Setup (Ubuntu)

> ğŸ§° All instructions and shell scripts are provided.

- Install Kafka & Zookeeper manually
- Start both with shell scripts
- Kafka CLI: Create topic, produce/consume messages
- Handle connection errors and permissions

---

## âš™ï¸ CLI Commands

```bash
# Create Topic
kafka-topics.sh --create --bootstrap-server localhost:9092 --topic test-topic --partitions 1 --replication-factor 1

# Produce Message
kafka-console-producer.sh --broker-list localhost:9092 --topic test-topic

# Consume Message
kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test-topic --from-beginning
```


---

## ğŸ Kafka with Python

* Install Python Kafka client:
  ```bash
  pip install kafka-python
  ```
* Build:
  * `producer.py` â€” sends messages to Kafka
  * `consumer.py` â€” consumes messages from Kafka
* Implement JSON serialization & deserialization
* Real-time producer that reads system logs

---

## ğŸ“ˆ Real-Time Log Processor Project

âœ… A complete Kafka-based pipeline to stream logs in real-time.

### Features:

* Real-time log ingestion from `/var/log`
* Kafka producer continuously streams logs
* Kafka consumer processes logs
* Filters and downloads error/critical logs

---

## ğŸ“Š Streamlit UI for Logs

* View logs in real-time on web UI
* Filter by keywords (e.g., "error", "critical")
* Download filtered logs
* Auto refresh log panel

---

## ğŸ“¢ Notification for Critical Logs

* Sends desktop notifications when "CRITICAL" or "ERROR" logs appear
* `notify2` used with fallback to console alerts
* Customize actions for future (Slack, Email, SMS)

---

## ğŸ³ Kafka with Docker Compose

Easiest way to run Kafka locally:

* Services: Kafka + Zookeeper (+ Kafka UI optional)
* Full `docker-compose.yml` included
* Bonus: Kafka UI for monitoring topics visually

---

## â˜ï¸ Kafka on Confluent Cloud / AWS MSK

### âœ… Confluent Cloud

* Fully managed Kafka-as-a-Service
* Easily integrate Python clients
* Secure with API Keys

### âœ… AWS MSK

* Managed Kafka cluster inside AWS VPC
* Best for large-scale AWS-native workloads
* Python code works with minor network setup

---

## ğŸ§  Advanced Kafka

* **Kafka Streams** â€” stream processing within Kafka
* **Kafka Connect** â€” integration with external data sources
* **Schema Registry & Avro** â€” enforce data schemas
* **Monitoring** â€” JMX, Kafka UI, Confluent Control Center
* **Security** â€” SSL, SASL, ACL, encryption

---

## ğŸ”š Conclusion

This project is a complete Kafka ecosystem guide for Python developers. By following this journey, youâ€™ve:

âœ… Learned Kafka architecture

âœ… Built Python-based Kafka apps

âœ… Visualized streaming data

âœ… Integrated notifications

âœ… Understood production deployment strategies

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ producer.py
â”œâ”€â”€ consumer.py
â”œâ”€â”€ kafka_streamlit_ui.py
â”œâ”€â”€ log_notifier.py
â”œâ”€â”€ README.md
â”œâ”€â”€ kafka_start.sh
â””â”€â”€ logs/
```

---

## ğŸ’¡ Next Steps

* Add REST Proxy to expose Kafka via APIs
* Use Kafka Connect to stream from databases
* Deploy real-time dashboards with Grafana
* Host on Kubernetes or cloud services

---

## ğŸ“¬ Questions or Contributions?

Feel free to raise issues or submit PRs. Happy Kafka-ing! ğŸ§¡
